{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO PIPELINE - detect poacher on an inputed video \n",
    "----\n",
    "\n",
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poacher.model import (yolo_loss)\n",
    "from poacher import utils\n",
    "from poacher import config\n",
    "from poacher import metrics\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "print('tensorflow version:', tf.__version__)\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    tf.per_process_gpu_memory_fraction = 0.3\n",
    "    print('Using GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    model = tf.keras.models.load_model(model_path, compile=False)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss={\n",
    "                      'tf_op_layer_concat_4': lambda y_true, y_pred: yolo_loss(y_true, y_pred), # 52x52\n",
    "                      'tf_op_layer_concat_7': lambda y_true, y_pred: yolo_loss(y_true, y_pred), # 26x26\n",
    "                      'tf_op_layer_concat_10': lambda y_true, y_pred: yolo_loss(y_true, y_pred),# 13x13\n",
    "                  }\n",
    "                 )\n",
    "    print('model loaded in %.2fs'%(time.time() - t0))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded in 7.96s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'save/20200417_model_trained.h5'\n",
    "model = load_model(model_path)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'tf_op_layer_concat_4/Identity:0' shape=(None, None, None, None, None) dtype=float32>,\n",
       " <tf.Tensor 'tf_op_layer_concat_7/Identity:0' shape=(None, None, None, None, None) dtype=float32>,\n",
       " <tf.Tensor 'tf_op_layer_concat_10/Identity:0' shape=(None, None, None, None, None) dtype=float32>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load video and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_frame(vid):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Get next frame\n",
    "    return_value, frame = vid.read()\n",
    "    \n",
    "    # If there is a frame then change color scale\n",
    "    if return_value:\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        return frame\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def image_preprocess(image, target_size):\n",
    "\n",
    "    ih, iw    = target_size\n",
    "    h,  w, _  = image.shape\n",
    "\n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh  = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "\n",
    "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
    "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
    "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "    image_paded = image_paded / 255.\n",
    "\n",
    "    return image_paded\n",
    "\n",
    "def get_image_preprocess(frame):\n",
    "\n",
    "    input_size = config.INPUT_SIZE\n",
    "    # Preprocess image (change size and convert to np array)\n",
    "    frame_size = frame.shape[:2]\n",
    "    image_data = image_preprocess(np.copy(frame), [input_size, input_size])\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "    \n",
    "    return image_data\n",
    "\n",
    "def predict(X, model):\n",
    "    t0 = time.time()\n",
    "    pred = model.predict_on_batch(X)\n",
    "    return pred, time.time() - t0\n",
    "\n",
    "def postprocess_pred_bbox(pred_bbox, frame_size):\n",
    "    \n",
    "    input_size = config.INPUT_SIZE\n",
    "    threshold = config.THRESHOLD\n",
    "    \n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "    \n",
    "    bboxes = utils.postprocess_boxes(pred_bbox, frame_size, input_size, threshold)\n",
    "    \n",
    "    # Keep only person object prediction\n",
    "    bboxes = bboxes[bboxes[..., 5] == 0]\n",
    "\n",
    "    bboxes = utils.nms(bboxes, 0.45, method='nms')    \n",
    "    return bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path, out_path='test.mp4', break_at=60, frames_to_ignore=0, verbose=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    t_start = time.time()\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    fps = round(vid.get(cv2.CAP_PROP_FPS),0)\n",
    "    \n",
    "    times = {\n",
    "        'next frame': list(),\n",
    "        'write time': list(),\n",
    "        'preprocess time': list(),\n",
    "        'pred time': list(),\n",
    "        'postprocess time': list(),\n",
    "        'draw bboxes time': list()\n",
    "    }\n",
    "    frames_analysed = 0\n",
    "    \n",
    "    cnt = 0\n",
    "    # get first frame\n",
    "    frame = get_next_frame(vid)\n",
    "    \n",
    "    # video resolution\n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    frames_hist = list()\n",
    "    \n",
    "    print('Original video: %ix%i and %i fps'%(width, height, fps))\n",
    "    \n",
    "    out = cv2.VideoWriter(out_path, \n",
    "                          cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                          fps, (width, height))\n",
    "    \n",
    "    print('Ready to analyse video at %.2fs'%(time.time()-t_start))\n",
    "    pred_bbox = []\n",
    "    \n",
    "    while frame is not None:\n",
    "        \n",
    "        if cnt%(frames_to_ignore+1) == 0:\n",
    "            # Preprocess frame\n",
    "            t0 = time.time()\n",
    "            image_data = get_image_preprocess(frame)\n",
    "            times['preprocess time'].append(time.time() - t0)\n",
    "\n",
    "            # Predict\n",
    "            pred_bbox, t = predict(image_data, model)\n",
    "            times['pred time'].append(t)\n",
    "            \n",
    "            # Postprocess to know if there is any poacher on the image\n",
    "            t0 = time.time()\n",
    "            pred_bbox = postprocess_pred_bbox(pred_bbox, [height, width])\n",
    "            times['postprocess time'].append(time.time() - t0)\n",
    "            \n",
    "            if verbose is not None:\n",
    "                print('frame nÂ°%i : %i poacher(s) detected'%(cnt, len(pred_bbox)))\n",
    "            \n",
    "            frames_analysed += 1\n",
    "            gc.collect()\n",
    "            \n",
    "        \n",
    "        # Draw box on image\n",
    "        t0 = time.time()\n",
    "        frame = utils.draw_bbox(frame, pred_bbox)\n",
    "        times['draw bboxes time'].append(time.time() - t0)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        out.write(frame)\n",
    "        times['write time'].append(time.time() - t0)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        frame = get_next_frame(vid)\n",
    "        times['next frame'].append(time.time() - t0)\n",
    "        \n",
    "        cnt += 1\n",
    "        if cnt%fps == 0:\n",
    "            print(cnt,'frames : %.2fs'%(time.time()-t_start))\n",
    "            gc.collect()\n",
    "        \n",
    "        # Break if ask\n",
    "        if break_at is not None:\n",
    "            if cnt >= break_at:\n",
    "                break\n",
    "                \n",
    "    vid.release()\n",
    "    out.release()\n",
    "    \n",
    "    print('==================')\n",
    "    print('Script ended in %.2fs'%(time.time() - t_start))\n",
    "    print('Average time of writing into out video (%i frames) : %.3fs (std %.4f)'%(\n",
    "        cnt, np.mean(times['write time']), np.std(times['write time'])))\n",
    "    print('Average time of getting next frame (%i frames) : %.3fs (std %.4f)'%(\n",
    "        cnt, np.mean(times['next frame']), np.std(times['next frame'])))\n",
    "    print('Average time of preprocessing a frame (%i frames) : %.3fs (std %.4f)'%(\n",
    "        frames_analysed, np.mean(times['preprocess time']), np.std(times['preprocess time'])))\n",
    "    print('Average time of prediction on a frame (%i frames) : %.3fs (std %.4f)'%(\n",
    "        frames_analysed, np.mean(times['pred time']), np.std(times['pred time'])))\n",
    "    print('Average time of postprocess bboxes (%i frames) : %.3fs (std %.4f)'%(\n",
    "        frames_analysed, np.mean(times['postprocess time']), np.std(times['postprocess time'])))\n",
    "    print('Average time of drawing bboxes on a frame (%i frames) : %.3fs (std %.4f)'%(\n",
    "        cnt, np.mean(times['draw bboxes time']), np.std(times['draw bboxes time'])))\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/data/archives/1.1.11.MP4\"\n",
    "# video_path = \"/data/archives/1.1.1.mov\"\n",
    "# video_path = \"/data/savane_1min.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video: 3840x2160 and 30 fps\n",
      "Ready to analyse video at 0.68s\n",
      "30 frames : 11.30s\n",
      "60 frames : 23.04s\n",
      "90 frames : 34.04s\n",
      "120 frames : 44.68s\n",
      "150 frames : 55.65s\n",
      "180 frames : 66.19s\n",
      "210 frames : 76.50s\n",
      "240 frames : 87.01s\n",
      "270 frames : 97.53s\n",
      "300 frames : 108.18s\n",
      "330 frames : 118.92s\n",
      "360 frames : 129.44s\n",
      "390 frames : 139.98s\n",
      "420 frames : 151.02s\n",
      "450 frames : 161.97s\n",
      "480 frames : 172.94s\n",
      "510 frames : 183.97s\n",
      "540 frames : 195.03s\n",
      "570 frames : 206.00s\n",
      "600 frames : 217.14s\n",
      "==================\n",
      "Script ended in 218.72s\n",
      "Average time of writing into out video (604 frames) : 0.083s (std 0.0086)\n",
      "Average time of getting next frame (604 frames) : 0.021s (std 0.0121)\n",
      "Average time of preprocessing a frame (302 frames) : 0.009s (std 0.0016)\n",
      "Average time of prediction on a frame (302 frames) : 0.374s (std 0.0290)\n",
      "Average time of postprocess bboxes (302 frames) : 0.007s (std 0.0009)\n",
      "Average time of drawing bboxes on a frame (604 frames) : 0.001s (std 0.0008)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "times = main(video_path, break_at=None, frames_to_ignore=1, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preds_time = times['pred time']\n",
    "plt.hist(preds_time, 15, density=True)\n",
    "plt.title('Inference time over 302 frames')\n",
    "plt.xlabel('time (in sec)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
