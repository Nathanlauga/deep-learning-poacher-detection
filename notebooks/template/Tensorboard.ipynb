{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def true_predict(y_true, y_pred):\n",
    "    result = 0\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "#     for i in range(y_pred.shape):\n",
    "#         if y_pred[i] == y_true[i]:\n",
    "#             result += 1\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# model.fit(x=x_train, \n",
    "#           y=y_train, \n",
    "#           epochs=5, \n",
    "#           validation_data=(x_test, y_test), \n",
    "#           callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/fit --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 0\n",
      "[2.3905091, 0.08188889, 0.1]\n",
      "9000/9000 [==============================] - 1s 87us/sample - loss: 2.0599 - accuracy: 0.3842 - mean_pred: 0.1000\n",
      "999/999 [==============================] - 0s 54us/sample - loss: 2.0348 - accuracy: 0.4434 - mean_pred: 0.1000\n",
      "[2.08571, 0.3278328, 0.09999997]\n",
      "9000/9000 [==============================] - 0s 46us/sample - loss: 1.8302 - accuracy: 0.5916 - mean_pred: 0.1000\n",
      "999/999 [==============================] - 0s 52us/sample - loss: 1.8007 - accuracy: 0.5926 - mean_pred: 0.1000\n",
      "[1.8360054, 0.5408541, 0.09999997]\n",
      "9000/9000 [==============================] - 1s 56us/sample - loss: 1.5997 - accuracy: 0.6829 - mean_pred: 0.1000\n",
      "999/999 [==============================] - 0s 59us/sample - loss: 1.6364 - accuracy: 0.6737 - mean_pred: 0.1000\n",
      "[1.6397318, 0.63756377, 0.09999997]\n",
      "9000/9000 [==============================] - 0s 43us/sample - loss: 1.4262 - accuracy: 0.7367 - mean_pred: 0.1000\n",
      "999/999 [==============================] - 0s 51us/sample - loss: 1.4129 - accuracy: 0.7337 - mean_pred: 0.1000\n",
      "[1.4280629, 0.7120712, 0.09999997]\n",
      "9000/9000 [==============================] - 0s 42us/sample - loss: 1.2340 - accuracy: 0.7810 - mean_pred: 0.1000\n",
      "999/999 [==============================] - 0s 52us/sample - loss: 1.3162 - accuracy: 0.7357 - mean_pred: 0.1000\n",
      "[1.2238811, 0.7711771, 0.09999997]\n",
      "9000/9000 [==============================] - 0s 49us/sample - loss: 1.0550 - accuracy: 0.8262 - mean_pred: 0.1000\n",
      "999/999 [==============================] - 0s 63us/sample - loss: 0.9575 - accuracy: 0.8619 - mean_pred: 0.1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 10000\n",
    "nb_epochs = 1\n",
    "n_steps = int(len(x_train)/batch_size) #+1\n",
    "epoch_scores = list()\n",
    "epoch_scores_valid = list()\n",
    "\n",
    "val_split = 0.1\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# before training init writer (for tensorboard log) / model\n",
    "writer = tf.summary.create_file_writer(log_dir+'/train')\n",
    "writer_valid = tf.summary.create_file_writer(log_dir+'/valid')\n",
    "\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    print('start epoch', epoch)\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "\n",
    "        start = i\n",
    "        end_train = int(i+(batch_size*(1 - val_split)))\n",
    "        end = i + batch_size - 1\n",
    "\n",
    "        x_batch = x_train[start:end_train]\n",
    "        y_batch = y_train[start:end_train]\n",
    "\n",
    "        x_batch_valid = x_train[end_train:end]\n",
    "        y_batch_valid = y_train[end_train:end]\n",
    "\n",
    "        tmp = model.train_on_batch(x_batch, y_batch, reset_metrics=False)\n",
    "        print(tmp)\n",
    "\n",
    "        epoch_scores = model.evaluate(x_batch, y_batch)\n",
    "        epoch_scores_valid = model.evaluate(x_batch_valid, y_batch_valid)\n",
    "\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(name=\"loss\", data=epoch_scores[0], step=i)\n",
    "            tf.summary.scalar(name=\"accuracy\", data=epoch_scores[1], step=i)\n",
    "            tf.summary.scalar(name=\"mean_pred\", data=epoch_scores[2], step=i)\n",
    "            writer.flush()\n",
    "\n",
    "        with writer_valid.as_default():\n",
    "            tf.summary.scalar(name=\"loss\", data=epoch_scores_valid[0], step=i)\n",
    "            tf.summary.scalar(name=\"accuracy\", data=epoch_scores_valid[1], step=i)\n",
    "            tf.summary.scalar(name=\"mean_pred\", data=epoch_scores_valid[2], step=i)\n",
    "            writer_valid.flush()\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6044667162685164\n"
     ]
    }
   ],
   "source": [
    "oui = np.mean(epoch_scores, axis=0)\n",
    "print(oui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
